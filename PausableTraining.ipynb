{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Objective "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Develop a skeletal framework for long-term, indefinite training that is conducted in multiple, discrete sessions spread out over time.  We want to be able to train a network like this:\n",
    "- Hit the switch to start training.\n",
    "- Open up TensorBoard and see the graph of the loss function, check out the kernels, etc.\n",
    "- Wait for a while, refresh TensorBoard, and see how things are coming along.\n",
    "- Hit some kind of *save and quit* button.  Not sure how best to do this, but an easy way would be for the code to check for the existence of a file called \"pause\" in the training dir.  To pause the training, you'd go to a bash prompt and do \"touch pause\".  \n",
    "- Come back later, fire it up again, and hit a *continue* button that resumes training from where we left off."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Next Objective\n",
    "Provide a way to load up the state of the network from earlier points in time.  Local minima in the training loss. Then we can test or validate those and package up the best one for \"release\" (e.g. Kaggle submission)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Graph "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We just need dummy operations.  No need to saddle the framework with actual machine learning.  So, we'll simulate training with looping counter called $p$.  The \"network output\" is simply the constant function $f(x) = p$.  It has one trainable parameter: $p$.  We won't actually feed it any input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "graph = tf.Graph()\n",
    "with graph.as_default():\n",
    "    p = tf.get_variable(name=\"tf_p\", \n",
    "                        shape=[1], \n",
    "                        initializer=tf.constant_initializer(0),\n",
    "                       dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training Operation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Actually...  Instead of doing addition modulo n, what happens when an int variable overflows in TensorFlow?  Let's find out (while we're here anyway).  **Ans: \"Inf\"** *(increase learning rate and/or $p$ to see)*\n",
    "\n",
    "We need to follow TF conventions here, so we'll use a proper tf.learn.Optimizer to do our \"training.\"  The simplest one seems to be GradientDescent, so we'll use that and fake the \"loss\" function in order to make our parameter increment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with graph.as_default():\n",
    "    \n",
    "    # Fake loss function to make the optimizer think p always needs to be adjusted by +2\n",
    "    loss = -2 * tf.ones([1])\n",
    "\n",
    "    # Step counter\n",
    "    global_step = tf.Variable(0, name=\"global_step\", trainable=False)\n",
    "    \n",
    "    # Normally we'd run minimize(), which first computes the gradients and then applies them.\n",
    "    # Here, we want to fool the optimizer with a fake (gradient, variable-to-train) pair and then apply that.\n",
    "    # So, we'll run just the second half of minimize() and fake the first half.\n",
    "    grads_and_vars = [(loss, p)]\n",
    "    train_op = tf.train.GradientDescentOptimizer(learning_rate=1.0).apply_gradients(grads_and_vars, global_step=global_step)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "#### Test train_op in a simple session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false,
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step   1:\tp = 2.000000\n",
      "step 101:\tp = 202.000000\n",
      "step 201:\tp = 402.000000\n",
      "step 301:\tp = 602.000000\n",
      "step 401:\tp = 802.000000\n",
      "step 501:\tp = 1002.000000\n",
      "step 601:\tp = 1202.000000\n",
      "step 701:\tp = 1402.000000\n",
      "step 801:\tp = 1602.000000\n",
      "step 901:\tp = 1802.000000\n"
     ]
    }
   ],
   "source": [
    "with tf.Session(graph=graph) as s:\n",
    "    \n",
    "    # Initialize the network parameters\n",
    "    tf.global_variables_initializer().run()\n",
    "    \n",
    "    for i in range(1000):\n",
    "        _, y, gstep = s.run([train_op, p, global_step])\n",
    "        if (i % 100 == 0):\n",
    "            print(\"step %3d:\\tp = %f\" % (gstep,y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training Session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "navigate_num": "#000000",
    "navigate_text": "#333333",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700",
    "sidebar_border": "#EEEEEE",
    "wrapper_background": "#FFFFFF"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "104px",
    "width": "252px"
   },
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 4,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": false,
   "widenNotebook": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
