{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Objective "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Develop a skeletal framework for long-term, indefinite training that is conducted in multiple, discrete sessions spread out over time.  We want to be able to train a network like this:\n",
    "- Hit the switch to start training.\n",
    "- Open up TensorBoard and see the graph of the loss function, check out the kernels, etc.\n",
    "- Wait for a while, refresh TensorBoard, and see how things are coming along.\n",
    "- Hit some kind of \"pause button\" and shut everything down for a while.\n",
    "- Come back later, fire it up again, and it picks up right where it left off without misssing a beat.\n",
    "- Furthermore, if it ever crashes, we want to be able to resume from a recent checkpoint so we don't lose too much work."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build the Graph "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We just need dummy operations.  No need to saddle the framework with actual machine learning.  So, we'll use just one trainable parameter called $p$ and we won't bother feeding any input to it.  The \"network output\" is simply the constant function $f() = p$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "graph = tf.Graph()\n",
    "with graph.as_default():\n",
    "    p = tf.get_variable(name=\"p\", \n",
    "                        shape=[1], \n",
    "                        initializer=tf.constant_initializer(0),\n",
    "                        dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training Operation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To make this at least somewhat realistic (not *too* far off from a real application), we'll make a proper **train_op** using a `tf.train.Optimizer`.\n",
    "\n",
    "`tf.train.GradientDescent` is the simplest one, so let's go with that.\n",
    "\n",
    "To simulate training, we'll just increment our trainable parameter $p$ by (oh, let's say) 2 at every training step.  The straightforward way to do this would be to use a loss function with a constant gradient of -2 (e.g. loss$(x) = -2x + c$).  That would require setting up an input placeholder for $x$, though, and we don't want to clutter up the framework with unnecessary variables.\n",
    "\n",
    "So, instead of calling `tf.train.GradientDescentOptimizer.minimize(loss)`--which takes the gradient of the loss function and then applies it to the trainable parameters--we'll take a detour around the gradient-taking part and call `tf.train.GradientDescentOptimizer.apply_gradients(grad)` directly.  We need to pass it a tensor `grad` which it will assume is the gradient of the loss.  It'll be none the wiser if we just give it -2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with graph.as_default():\n",
    "    \n",
    "    # Step counter\n",
    "    global_step = tf.Variable(0, name=\"global_step\", trainable=False)\n",
    "    \n",
    "    # Fake the gradient of a loss function to make the optimizer think p always needs to be adjusted by +2\n",
    "    fake_loss_gradient = -2 * tf.ones([1])\n",
    "\n",
    "    # Simulate calling compute_gradients() (the first half of minimize())\n",
    "    grads_and_vars = [(fake_loss_gradient, p)]\n",
    "    \n",
    "    # Set train_op to be the apply_gradients part of minimize()\n",
    "    train_op = tf.train.GradientDescentOptimizer(learning_rate=1.0).apply_gradients(grads_and_vars, global_step=global_step)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test train_op in a simple session"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Just for a sanity check, let's run our train_op in an old-fashioned tf.Session.  For the real training, we'll use a tf.train.Supervisor.managed_session() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 100:\tp = 200.000000\n",
      "step 200:\tp = 400.000000\n",
      "step 300:\tp = 600.000000\n",
      "step 400:\tp = 800.000000\n",
      "step 500:\tp = 1000.000000\n"
     ]
    }
   ],
   "source": [
    "with tf.Session(graph=graph) as s:\n",
    "    \n",
    "    # Initialize the network parameters\n",
    "    tf.global_variables_initializer().run()\n",
    "    \n",
    "    for i in range(500):\n",
    "        _, y, gstep = s.run([train_op, p, global_step])\n",
    "        if (gstep % 100 == 0):\n",
    "            print(\"step %3d:\\tp = %f\" % (gstep,y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks good.  Now let's do it with a pausable session."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training Session"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TensorFlow supports saving and loading the network parameters using the `tf.train.Saver` class. Since we want checkpoints, however, we can make this easier by using a `tf.train.Supervisor.managed_session` instead of the usual `tf.Session`.  \n",
    "\n",
    "A `managed_session` has its own Saver and it will save checkpoints automatically and reload from them.  The only thing it leaves for us to do is to implement is the \"pause button.\"  To do that, we'll periodically check the training directory for a file named \"pause\".  If one exists, we'll delete it (in preparation for the next use), save a checkpoint manually, and then shut down the training.\n",
    "\n",
    "**BEFORE RUNNING THE NEXT CELL** get a terminal open and have this command ready to go:\n",
    "```\n",
    "touch /tmp/pausable_training/pause\n",
    "```\n",
    "\n",
    "**NB**: Only the *values* of the network parameters are saved and reloaded--not the network topology itself.  We still have to build the graph and if there's input (which there usually is), load it.  The step we skip is the network initialization step (`tf.global_variables_initializer().run()`).  Obviously, we have to leave that to `managed_session()` since we want it to handle the task of choosing whether to reload values from storage or initialize them from scratch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from /tmp/pausable_training/pt.ckpt-1900\n",
      "INFO:tensorflow:global_step/sec: 0\n",
      "step 2000:\tp = 4000.000000\n",
      "step 2100:\tp = 4200.000000\n",
      "step 2200:\tp = 4400.000000\n",
      "step 2300:\tp = 4600.000000\n",
      "step 2400:\tp = 4800.000000\n",
      "step 2500:\tp = 5000.000000\n",
      "Pause command received.  Saving checkpoint and shutting down.\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "training_dir = \"/tmp/pausable_training/\"\n",
    "pause_file = training_dir + \"pause\"\n",
    "checkpoint_file = training_dir + \"pt.ckpt\"\n",
    "\n",
    "with graph.as_default():\n",
    "    sv = tf.train.Supervisor(logdir=training_dir)\n",
    "    with sv.managed_session() as s:\n",
    "\n",
    "        # Supervisor calls tf.global_variables_initializer().run() for us\n",
    "\n",
    "        while not sv.should_stop():\n",
    "            _, y, gstep = s.run([train_op, p, global_step])\n",
    "            if (gstep % 100 == 0):\n",
    "                print(\"step %3d:\\tp = %f\" % (gstep,y))\n",
    "                if (tf.gfile.Exists(pause_file)):\n",
    "                    sv.Stop()\n",
    "                time.sleep(1)\n",
    "                \n",
    "        if tf.gfile.Exists(pause_file):\n",
    "            print(\"Pause command received.  Saving checkpoint and shutting down.\")\n",
    "            tf.gfile.Remove(pause_file)\n",
    "            sv.saver.save(s, checkpoint_file, global_step=global_step)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now, we shut down and continue with more training later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Kill the kernel, forcing it to restart - NB: You'll have to step manually from here on.\n",
    "import os\n",
    "os._exit(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Re-run the notebook at this point to perform subsequent training sessions.  Each time it will pick up where it left off (unless the training directory has been wiped).  Note the reported \"step\" numbers above to see it resuming."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Next Objectives\n",
    "#### Make this a little less skeletal \n",
    "Use input data and actually train some simple parameters (call `minimize`) so we have a real train_op.  Try logistic regression on a randomly-generated dataset.\n",
    "#### Get a better handle on TensorBoard reporting  \n",
    "Want to see the loss and the trainable parameters at the very least.  Eventually we'll add learning rates, kernels, etc.\n",
    "#### Keep a roster of the top performers\n",
    "Keep snapshots of the networks corresponding to local minima in the training loss.  Make it easy to load those snapshots.  Once we suspect we're beginning to overtrain the network, we can load up those \"training highlights\", cross-validate them, and package up the best one for \"release\" (e.g. Kaggle submission).\n",
    "#### Use a file input queue\n",
    "We want to operate on lots of data: more then what will fit main memory.  See this page: https://www.tensorflow.org/programmers_guide/reading_data"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "navigate_num": "#000000",
    "navigate_text": "#333333",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700",
    "sidebar_border": "#EEEEEE",
    "wrapper_background": "#FFFFFF"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "104px",
    "width": "252px"
   },
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 4,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": false,
   "widenNotebook": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
