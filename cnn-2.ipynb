{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "4embtkV0pNxM"
   },
   "source": [
    "Simple CNN for notMNIST with Decoupled Training/Testing Phases\n",
    "=============\n",
    "In cnn-1, the network was created, trained, tested, and then scrapped--all in a single TensorFlow session.  In this version, the network will be trained in a pausable session and all the information needed to rebuild it will be saved.  Then it will be tested in a separate session.  This kind of separation is obviously necessary for doing anything serious with a network (like submitting it for a Kaggle competition)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "cellView": "both",
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "collapsed": false,
    "id": "tm2CQN_Cpwj0"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from six.moves import cPickle as pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Input Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "cellView": "both",
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "output_extras": [
      {
       "item_id": 1
      }
     ]
    },
    "colab_type": "code",
    "collapsed": false,
    "executionInfo": {
     "elapsed": 11948,
     "status": "ok",
     "timestamp": 1446658914837,
     "user": {
      "color": "",
      "displayName": "",
      "isAnonymous": false,
      "isMe": true,
      "permissionId": "",
      "photoUrl": "",
      "sessionId": "0",
      "userId": ""
     },
     "user_tz": 480
    },
    "id": "y3-cj1bpmuxc",
    "outputId": "016b1a51-0290-4b08-efdb-8c95ffc3cd01"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set (200000, 28, 28) (200000,)\n"
     ]
    }
   ],
   "source": [
    "pickle_file = '../notMNIST.pickle'\n",
    "\n",
    "with open(pickle_file, 'rb') as f:\n",
    "    save = pickle.load(f)\n",
    "    train_dataset = save['train_dataset']\n",
    "    train_labels = save['train_labels']\n",
    "    del save  # hint to help gc free up memory\n",
    "    print('Training set', train_dataset.shape, train_labels.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing $\\cdot$ Normalization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apparently, these networks learn better if the input data (the pixel values, in this context) have a mean of 0 and a variance of 1 [citation needed].  So, we want to adjust the pixel values a bit before we dump them into the machine.  In a future worksheet we'll also compute and subtract the mean *image* (i.e. given pixel coordiates i,j find the mean value of pixel (i,j) across all images in the dataset; do this for each i,j).\n",
    "\n",
    "Let $K = N \\times H \\times W$, where $N$ is the number of images, $H$ is the height of each image, and $W$ is the width.  Let $x_1, x_2, \\ldots, x_K$ be the big list of all the pixel values from all the training images.\n",
    "\n",
    "Getting a mean of 0 is easy.  Just compute the mean $\\mu$ of the pixels in the training data and subtract that from each of them.  We'll also need treat that $\\mu$ as an estimator of the mean of our other datasets and subtract it from them too.  \n",
    "\n",
    "But how do we get varianace 1?  Well, after that first step, our new pixel values will be $x_i' = (x_i-\\mu)$.  We can adjust the variance of those pixels by scaling them.  So, we're looking for a scalar $c$ that will make those values $c(x_i-\\mu)$ have a variance of 1.  The variance of these adjusted pixels is given by this expression (where $\\sigma^2$ is the variance of the original pixels):\n",
    "\n",
    "$$\\begin{eqnarray}\n",
    "\\sum_1^N \\left(c \\left(x_i - \\mu\\right)\\right)^2\n",
    "&=& c^2 \\sum_1^N \\left(x_i - \\mu\\right)^2\\\\\n",
    "&=& c^2 \\sigma^2\\\\\n",
    "\\end{eqnarray}$$\n",
    "\n",
    "So, there you go.  Our scalar $c = \\frac 1 \\sigma$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mu = -0.081865, sigma = 0.454264\n"
     ]
    }
   ],
   "source": [
    "# Find mean and std. dev. of training data\n",
    "mu = np.mean(train_dataset)\n",
    "sigma = np.std(train_dataset)\n",
    "print('mu = %f, sigma = %f' % (mu, sigma))\n",
    "\n",
    "# Normalize dataset\n",
    "train_dataset = (train_dataset - mu) / sigma"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sanity Check"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see a histogram of those pixel values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAtwAAAIiCAYAAAD7MR8AAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nMNH/B80dUG+We2OKAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f75daae19b0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.mlab as mlab\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# the histogram of the data\n",
    "n, bins, patches = plt.hist(train_dataset.flatten(), 256)\n",
    "\n",
    "# The default y-tick labels are bizarre when y values are large\n",
    "ax = plt.gca()\n",
    "y_tick_labels = list(map((lambda t: \"%.1E\" % t), ax.get_yticks()))\n",
    "ax.set_yticklabels(y_tick_labels)\n",
    "\n",
    "plt.xlabel('Value')\n",
    "plt.ylabel('Occurrances')\n",
    "\n",
    "# The \"r\" prefix here means \"raw mode\" (don't treat \\ as an escape)\n",
    "# The \"y=1.08\" parameter prevents the title from overlapping with the chart\n",
    "plt.title(r'$\\mathrm{Histogram\\ of\\ Pixel\\ Values\\ in\\ Training\\ Dataset:}\\ \\mu= %.4f,\\ \\sigma=%.4f$' % (mu,sigma), y=1.08)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As one would guess from looking the pictures in the dataset, they're greyscale but almost completely monochromatic.  Take this, one, say..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAdcAAAHVCAYAAACjTLHKAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAADIDHIFAADIDHIFAADIzP8BYZyd+qEA4YIAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f75cd587ac8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Pick a random image from the training dataset\n",
    "i = np.random.randint(train_dataset.shape[0])\n",
    "im = train_dataset[i,:,:]\n",
    "plt.grid(False)\n",
    "plt.imshow(im)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Save Normalization Constants"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In cnn-1, we did all the training and testing together, so we could normalize all the datasets at once.\n",
    "\n",
    "In this worksheet, we can't do that because the training and testing phases are decoupled.  We need to save the $\\mu$ and $\\sigma$ we calculated for the training data and then reload them for the testing phase.  These stats aren't really part of the neural network, though; they're part of a preprocessing step.  So, we'll save them in a separate graph with a separate Saver.  \n",
    "\n",
    "Why not get a new $\\mu$ and $\\sigma$ directly from the testing data?\n",
    "\n",
    "Two reasons.  Firstly, those values from the training data form a \"lens\" through the which the network was trained to see input (it wasn't trained using the mean and std.dev. of the testing data).  Secondly, that would be \"cheating.\"  In a real-time application, it would not even possible to compute these statistics of the testing data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "g = tf.Graph()\n",
    "with g.as_default():\n",
    "    tf_mu = tf.Variable(name=\"tf_mu\", dtype=tf.float32, initial_value=mu)\n",
    "    tf_sigma = tf.Variable(name=\"tf_sigma\", dtype=tf.float32, initial_value=sigma)\n",
    "with tf.Session(graph=g) as s:\n",
    "    tf.global_variables_initializer().run()\n",
    "    metadata_saver = tf.train.Saver(var_list=[tf_mu, tf_sigma])\n",
    "    metadata_saver.save(s, '/tmp/cnn-2-stats.tfsaver')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "L7aHrm6nGDMB"
   },
   "source": [
    "### Preprocessing: Reformat data into a TensorFlow-friendly shapes\n",
    "- The design matrix is currently N x H x W, since they're greyscale images (no channel dimension like you'd get with colour images).  tf.nn.conv2d needs them formatted as N x H x W x #channels, however.  So we need to add a dimension at the end of the shape vector for the input data.\n",
    "- Labels need to be one-hot encoded floats."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def one_hot_encode(labels, num_categories):\n",
    "    '''Converts an array of labels to an array of one-hot-encoded labels.\n",
    "    [NB: Just noticed there's now a \"tf.one_hot\" function.  Should switch to that.]\n",
    "    Args:\n",
    "        labels: list (row vector) of N labels (where N is the number of examples)\n",
    "        num_categories: the number of possible labels\n",
    "    Returns:\n",
    "        N x num_categories array of one-hot encoded labels\n",
    "    '''\n",
    "    # IMPLEMENTATION\n",
    "    # np.expand_dims(labels, 1) is an Nx1 array (a.k.a. a column vector) \n",
    "    # [0..num_categories] == k is evaluated for each label k in the column vector\n",
    "    # This produces a one-hot vector [false, false, ..., true, false, ..., false] where \"true\" is in position k\n",
    "    # Then astype(float32) converts the array of booleans to an array of 0s and 1s (as floats)\n",
    "    return (np.arange(num_categories) == np.expand_dims(labels, 1)).astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pretend labels =  [6 8 6 7 8]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 0.,  0.,  0.,  0.,  0.,  0.,  1.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  1.,  0.],\n",
       "       [ 0.,  0.,  0.,  0.,  0.,  0.,  1.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  1.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  1.,  0.]], dtype=float32)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Testing one_hot_encode\n",
    "pretend_labels = np.random.randint(10, size=5)\n",
    "print(\"pretend labels = \", pretend_labels)\n",
    "one_hot_encode(pretend_labels, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "cellView": "both",
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "output_extras": [
      {
       "item_id": 1
      }
     ]
    },
    "colab_type": "code",
    "collapsed": false,
    "executionInfo": {
     "elapsed": 11952,
     "status": "ok",
     "timestamp": 1446658914857,
     "user": {
      "color": "",
      "displayName": "",
      "isAnonymous": false,
      "isMe": true,
      "permissionId": "",
      "photoUrl": "",
      "sessionId": "0",
      "userId": ""
     },
     "user_tz": 480
    },
    "id": "IRSyYiIIGIzS",
    "outputId": "650a208c-8359-4852-f4f5-8bf10e80ef6c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training dataset\t (200000, 28, 28, 1) \tTraining labels\t\t (200000, 10)\n"
     ]
    }
   ],
   "source": [
    "image_size = 28  # 32 for MNIST, but we're doing notMNIST\n",
    "num_labels = 10  # notMNIST is ABCDEFGHIJ, which is also 10 categories\n",
    "num_channels = 1 # grayscale\n",
    "\n",
    "with tf.name_scope(\"Training-Input\") as scope:\n",
    "    train_dataset = np.expand_dims(train_dataset, 3) # NxHxW --> NxHxWx1\n",
    "    train_labels = one_hot_encode(train_labels, num_labels)\n",
    "print('Training dataset\\t', train_dataset.shape, \"\\tTraining labels\\t\\t\", train_labels.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Computation Graph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with tf.name_scope(\"Hyperparameters\") as scope:\n",
    "    batch_size = 16\n",
    "    patch_size = 5    # kernel \n",
    "    depth = 16        # depth of first hidden layer\n",
    "    num_hidden = 64"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Graph and Set Up Placeholder Nodes in GPU Memory for the Input Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "graph = tf.Graph()\n",
    "with graph.as_default():\n",
    "    with tf.name_scope('Training-Input-Data'):\n",
    "        tf_train_dataset = tf.placeholder(tf.float32, shape=(batch_size, image_size, image_size, num_channels))\n",
    "        tf_train_labels  = tf.placeholder(tf.float32, shape=(batch_size, num_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Allocate and Initialize All Weights and Biases\n",
    "We'll use tf.get_variable instead of tf.Variable to make it easier for multi-GPU runs. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with graph.as_default():\n",
    "    \n",
    "    # First Conv Layer\n",
    "    with tf.variable_scope('ConvPoolRelu1'):\n",
    "        weights = tf.get_variable(name = \"weights\", \n",
    "                                  shape = (patch_size, patch_size, num_channels, depth), \n",
    "                                  initializer = tf.truncated_normal_initializer(mean = 0, \n",
    "                                                                               stddev = 0.1, \n",
    "                                                                               seed = None), \n",
    "                                  dtype = tf.float32)\n",
    "        biases = tf.get_variable(name = \"biases\",\n",
    "                                 shape = (depth),\n",
    "                                 initializer = tf.constant_initializer(0),\n",
    "                                 dtype = tf.float32)\n",
    "    # Second Conv Layer\n",
    "    with tf.variable_scope('ConvPoolRelu2'):  \n",
    "        weights = tf.get_variable(name = \"weights\", \n",
    "                                  shape = (patch_size, patch_size, depth, depth), \n",
    "                                  initializer = tf.truncated_normal_initializer(mean = 0, \n",
    "                                                                               stddev = 0.1, \n",
    "                                                                               seed = None), \n",
    "                                  dtype = tf.float32)\n",
    "        biases = tf.get_variable(name = \"biases\",\n",
    "                                 shape = (depth),\n",
    "                                 initializer = tf.constant_initializer(0),\n",
    "                                 dtype = tf.float32)\n",
    "    # First Fully-Connected Layer\n",
    "    with tf.variable_scope('FullyConnected3'):\n",
    "        weights = tf.get_variable(name = \"weights\", \n",
    "                                  shape = ((image_size//4)**2 * depth, num_hidden), \n",
    "                                  initializer = tf.truncated_normal_initializer(mean = 0, \n",
    "                                                                               stddev = 0.1, \n",
    "                                                                               seed = None), \n",
    "                                  dtype = tf.float32)\n",
    "        biases = tf.get_variable(name = \"biases\",\n",
    "                                 shape = (num_hidden),\n",
    "                                 initializer = tf.constant_initializer(0),\n",
    "                                 dtype = tf.float32)\n",
    "    # Second Fully-Connected Layer\n",
    "    with tf.variable_scope('FullyConnected4'):\n",
    "        weights = tf.get_variable(name = \"weights\", \n",
    "                                  shape = (num_hidden, num_labels), \n",
    "                                  initializer = tf.truncated_normal_initializer(mean = 0, \n",
    "                                                                               stddev = 0.1, \n",
    "                                                                               seed = None), \n",
    "                                  dtype = tf.float32)\n",
    "        biases = tf.get_variable(name = \"biases\",\n",
    "                                 shape = (num_labels),\n",
    "                                 initializer = tf.constant_initializer(0),\n",
    "                                 dtype = tf.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Layer-building Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def conv_pool_relu_layer(X, W, b):\n",
    "    conv_X = tf.nn.conv2d(X, W, [1, 1, 1, 1], padding='SAME')\n",
    "    pool_conv_X = tf.nn.max_pool(conv_X, [1,2,2,1], [1,2,2,1], padding='SAME')\n",
    "    relu_pool_conv_X = tf.nn.relu(pool_conv_X + b)\n",
    "    return relu_pool_conv_X\n",
    "\n",
    "def fc_layer(X, W, b):\n",
    "    return tf.matmul(X, W) + b\n",
    "\n",
    "def flatten_activation_map(x):\n",
    "    \"\"\"Converts a 4D tensor into a 2D tensor (so it can be fed to a fully-connected layer).\n",
    "    Args:\n",
    "        x: tensor with shape (N, H, W, C)\n",
    "    Returns:\n",
    "        tensor with shape (N, H*W*C)\n",
    "    \"\"\"\n",
    "    s = x.get_shape().as_list()\n",
    "    return tf.reshape(x, [s[0], -1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Network-assembly Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def model(data):\n",
    "    \"\"\"Retrieves the weights and biases and constructs the computation graph with them.\n",
    "    Args:\n",
    "        data: A batch tensor of input examples K x H x W x D (where K is the batch size)\n",
    "    Returns: the network output K x C (where C is the number of categories)\n",
    "    \"\"\"\n",
    "    with tf.variable_scope('ConvPoolRelu1', reuse=True):\n",
    "        W = tf.get_variable(\"weights\")\n",
    "        B = tf.get_variable(\"biases\")\n",
    "        layer_1_output = conv_pool_relu_layer(data, W, B)\n",
    "    with tf.variable_scope('ConvPoolRelu2', reuse=True):\n",
    "        W = tf.get_variable(\"weights\")\n",
    "        B = tf.get_variable(\"biases\")\n",
    "        layer_2_output = conv_pool_relu_layer(layer_1_output, W, B)\n",
    "        flat_X = flatten_activation_map(layer_2_output)\n",
    "    with tf.variable_scope('FullyConnected3', reuse=True):\n",
    "        W = tf.get_variable(\"weights\")\n",
    "        B = tf.get_variable(\"biases\")\n",
    "        fc1_layer_output = tf.nn.relu(fc_layer(flat_X, W, B))\n",
    "    with tf.variable_scope('FullyConnected4', reuse=True):\n",
    "        W = tf.get_variable(\"weights\")\n",
    "        B = tf.get_variable(\"biases\")\n",
    "        fc2_layer_output = fc_layer(fc1_layer_output, W, B)\n",
    "    return fc2_layer_output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interpret the Output, Set Up the Loss Function, Specify the Learning Algorithm "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "cellView": "both",
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "collapsed": false,
    "id": "IZYv70SvvOan"
   },
   "outputs": [],
   "source": [
    "with graph.as_default():\n",
    "    # Training computation.\n",
    "    logits = model(tf_train_dataset)\n",
    "    loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=logits, labels=tf_train_labels))\n",
    "    tf.summary.scalar(\"Loss\", loss)\n",
    "    global_step = tf.Variable(0, name='global_step', trainable=False)\n",
    "    train_op = tf.train.GradientDescentOptimizer(0.05).minimize(loss)\n",
    "\n",
    "    # Predictions for the training, validation, and test data.\n",
    "    train_prediction = tf.nn.softmax(logits)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training-related Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "cellView": "both",
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "AgQDIREv02p1"
   },
   "outputs": [],
   "source": [
    "def accuracy(predictions, labels):\n",
    "    '''\n",
    "    \"Grades\" a list of predictions (like marking a multiple choice test).\n",
    "    Accepts a list of one-hot predictions and a list of ground truth labels (the right answers) \n",
    "    Args:\n",
    "        predictions: NxK float array of one-hot-encoded network output, \n",
    "                     where N is the number of examples and K is the number of categories\n",
    "        labels: NxK array of one-hot-encoded ground truth labels (why one-hot encode those??)\n",
    "    Returns:\n",
    "        Percetage of correct predictions.\n",
    "    '''\n",
    "    # argmax(predictions, 1) gives the \"mostly likely\" category (\"one-decodes\" the network output)\n",
    "    # argmax(labels, 1) does the same thing \n",
    "    #    Why did we even one-hot encode those to begin with??\n",
    "    #    Ah... Right.  Because the loss function compares them to the network output.\n",
    "    # By putting the == inside a sum, we're implicitly casting the equality test to an int.\n",
    "    # Correct predictions yield 1, incorrect ones yield 0.\n",
    "    # Then we divide the tally of 1s by the number of predictions in the set.\n",
    "    return (100.0 * np.sum(np.argmax(predictions, 1) == np.argmax(labels, 1)) \n",
    "          / predictions.shape[0])\n",
    "\n",
    "def variable_summaries(var, name):\n",
    "    \"\"\"Attach a lot of summaries to a Tensor.\"\"\"\n",
    "    with tf.name_scope('summaries'):\n",
    "        mean = tf.reduce_mean(var)\n",
    "        tf.summary.scalar('mean/' + name, mean)\n",
    "        with tf.name_scope('stddev'):\n",
    "            stddev = tf.sqrt(tf.reduce_sum(tf.square(var - mean)))\n",
    "        tf.summary.scalar('sttdev/' + name, stddev)\n",
    "        tf.summary.scalar('max/' + name, tf.reduce_max(var))\n",
    "        tf.summary.scalar('min/' + name, tf.reduce_min(var))\n",
    "        tf.summary.histogram(name, var)\n",
    "    \n",
    "def clear_tensorboard_dir(path):\n",
    "    if tf.gfile.Exists(path):\n",
    "        tf.gfile.DeleteRecursively(path)\n",
    "    tf.gfile.MakeDirs(path)\n",
    "\n",
    "def make_batch(data, max_size, batch_num):\n",
    "    n = data.shape[0]\n",
    "    offset = (batch_num * max_size) % n\n",
    "    return data[offset:offset+max_size]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the Network and Save Its Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "both",
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "output_extras": [
      {
       "item_id": 37
      }
     ]
    },
    "colab_type": "code",
    "collapsed": false,
    "executionInfo": {
     "elapsed": 63292,
     "status": "ok",
     "timestamp": 1446658966251,
     "user": {
      "color": "",
      "displayName": "",
      "isAnonymous": false,
      "isMe": true,
      "permissionId": "",
      "photoUrl": "",
      "sessionId": "0",
      "userId": ""
     },
     "user_tz": 480
    },
    "id": "noKFb2UovVFR",
    "outputId": "28941338-2ef9-4088-8bd1-44295661e628",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training...\n",
      "\n",
      "Epoch 1 of 1\n",
      "-- 100% complete --\n",
      "Trained in 0:00:32.879681 at 0:00:32.879681 per epoch\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "from datetime import timedelta\n",
    "\n",
    "num_epochs = 1\n",
    "\n",
    "# Clear the tensorboard directory\n",
    "clear_tensorboard_dir(\"tensorboard\")\n",
    "\n",
    "with tf.Session(graph=graph) as session:\n",
    "    saver = tf.train.Saver()\n",
    "    merged_summaries = tf.summary.merge_all()\n",
    "    train_writer = tf.summary.FileWriter('./tensorboard', session.graph)\n",
    "    \n",
    "    # Initialize the variables on the GPU\n",
    "    tf.global_variables_initializer().run()\n",
    "\n",
    "    print('Training...')\n",
    "    start_time = time.time()\n",
    "    n_examples = train_dataset.shape[0]\n",
    "    batches_per_epoch = int(np.ceil(n_examples / batch_size))\n",
    "    for epoch in range(num_epochs):\n",
    "        print('\\nEpoch %d of %d' % ((epoch+1), num_epochs))\n",
    "        for batch in range(batches_per_epoch):\n",
    "            batch_data = make_batch(train_dataset, batch_size, batch)\n",
    "            batch_labels = make_batch(train_labels, batch_size, batch)\n",
    "            feed_dict = {tf_train_dataset: batch_data, tf_train_labels: batch_labels}\n",
    "            merged_sums, _, l, predictions = session.run([merged_summaries, train_op, loss, train_prediction], \n",
    "                                                         feed_dict=feed_dict)\n",
    "            # Progress report\n",
    "            if ((batch+1) % (batches_per_epoch // 100) == 0):\n",
    "                #train_writer.add_summary(merged_sums, batch)\n",
    "                print('\\r-- %d%% complete --' % (100*(batch+1) // batches_per_epoch), end=\"\")\n",
    "\n",
    "                # Save the variables to disk.\n",
    "                save_path = saver.save(session, \"/tmp/model.ckpt\")\n",
    "                #print(\"Model saved in file: %s\" % save_path)\n",
    "            \n",
    "    duration = timedelta(seconds=(time.time() - start_time))\n",
    "    print('\\nTrained in %s at %s per epoch' % (duration, duration / num_epochs))\n",
    "    \n",
    "    train_writer.close()    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing Phase\n",
    "Now, we want to **wipe memory clean** (restart the Jupyter notebook kernel) and load only the network parameters that the training session saved for us.  We also need to load up the testing data, and normalize it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Kill the kernel, forcing it to restart - NB: You'll have to step manually from here on.\n",
    "import os\n",
    "os._exit(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Unpickle the test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set (18724, 28, 28) (18724,)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from six.moves import cPickle as pickle\n",
    "\n",
    "pickle_file = '../notMNIST.pickle'\n",
    "\n",
    "with open(pickle_file, 'rb') as f:\n",
    "    save = pickle.load(f)\n",
    "    test_dataset = save['test_dataset']\n",
    "    test_labels = save['test_labels']\n",
    "    del save  # hint to help gc free up memory\n",
    "    print('Test set', test_dataset.shape, test_labels.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalize\n",
    "Start a session, create a saver, and use it to restore the graph so we can retrieve the $\\mu$ and $\\sigma$ constants.  We *could* get these in the main testing session, but it's nice to have the flexibility afforded by keeping these tasks in separate sessions (plus, the one-session way is obvious; the two-session way is challenging and useful so it has didactic value)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from /tmp/cnn-2-stats.tfsaver\n",
      "mu = -0.081865, sigma = 0.454264\n"
     ]
    }
   ],
   "source": [
    "g = tf.Graph()\n",
    "with g.as_default():\n",
    "    tf_mu = tf.Variable(name=\"tf_mu\", dtype=tf.float32, initial_value=0)\n",
    "    tf_sigma = tf.Variable(name=\"tf_sigma\", dtype=tf.float32, initial_value=0)\n",
    "with tf.Session(graph=g) as s:\n",
    "    metadata_saver = tf.train.Saver(var_list=[tf_mu, tf_sigma])\n",
    "    metadata_saver.restore(s, '/tmp/cnn-2-stats.tfsaver')\n",
    "    mu, sigma = s.run([tf_mu, tf_sigma])\n",
    "    print(\"mu = %f, sigma = %f\" % (mu, sigma))\n",
    "    \n",
    "    # Use mu and sigma as an estimator of the mean and std. dev. of the test dataset and normalize it\n",
    "    test_dataset = (test_dataset - mu) / sigma"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Computation Graph (Again) $\\cdot$ Testing Phase"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test_batch_size = 1000  # no need to overthink think this one; just find a size that fits on the GPU    \n",
    "patch_size = 5    # kernel \n",
    "depth = 16        # depth of first hidden layer\n",
    "num_hidden = 64\n",
    "image_size = 28\n",
    "num_channels = 1\n",
    "num_labels = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Create Graph and Set Up Placeholder Nodes in GPU Memory for the Input Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "testing_graph = tf.Graph()\n",
    "with testing_graph.as_default():\n",
    "    with tf.name_scope('Testing-Input-Data'):\n",
    "        tf_test_dataset = tf.placeholder(tf.float32, shape=(test_batch_size, image_size, image_size, num_channels))\n",
    "        tf_test_labels  = tf.placeholder(tf.float32, shape=(test_batch_size, num_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Allocate and Initialize All Weights and Biases\n",
    "This time we don't have to worry about initialization. The Saver will do that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "with testing_graph.as_default():\n",
    "    \n",
    "    # First Conv Layer\n",
    "    with tf.variable_scope('ConvPoolRelu1'):\n",
    "        weights = tf.get_variable(name = \"weights\", \n",
    "                                  shape = (patch_size, patch_size, num_channels, depth), \n",
    "                                  dtype = tf.float32)\n",
    "        biases = tf.get_variable(name = \"biases\",\n",
    "                                 shape = (depth),\n",
    "                                 dtype = tf.float32)\n",
    "    # Second Conv Layer\n",
    "    with tf.variable_scope('ConvPoolRelu2'):  \n",
    "        weights = tf.get_variable(name = \"weights\", \n",
    "                                  shape = (patch_size, patch_size, depth, depth), \n",
    "                                  dtype = tf.float32)\n",
    "        biases = tf.get_variable(name = \"biases\",\n",
    "                                 shape = (depth),\n",
    "                                 dtype = tf.float32)\n",
    "    # First Fully-Connected Layer\n",
    "    with tf.variable_scope('FullyConnected3'):\n",
    "        weights = tf.get_variable(name = \"weights\", \n",
    "                                  shape = ((image_size//4)**2 * depth, num_hidden), \n",
    "                                  dtype = tf.float32)\n",
    "        biases = tf.get_variable(name = \"biases\",\n",
    "                                 shape = (num_hidden),\n",
    "                                 dtype = tf.float32)\n",
    "    # Second Fully-Connected Layer\n",
    "    with tf.variable_scope('FullyConnected4'):\n",
    "        weights = tf.get_variable(name = \"weights\", \n",
    "                                  shape = (num_hidden, num_labels), \n",
    "                                  dtype = tf.float32)\n",
    "        biases = tf.get_variable(name = \"biases\",\n",
    "                                 shape = (num_labels),\n",
    "                                 dtype = tf.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Layer-building Functions (Again)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "(Should import these from a file so they aren't copied/pasted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def conv_pool_relu_layer(X, W, b):\n",
    "    conv_X = tf.nn.conv2d(X, W, [1, 1, 1, 1], padding='SAME')\n",
    "    pool_conv_X = tf.nn.max_pool(conv_X, [1,2,2,1], [1,2,2,1], padding='SAME')\n",
    "    relu_pool_conv_X = tf.nn.relu(pool_conv_X + b)\n",
    "    return relu_pool_conv_X\n",
    "\n",
    "def fc_layer(X, W, b):\n",
    "    return tf.matmul(X, W) + b\n",
    "\n",
    "def flatten_activation_map(x):\n",
    "    \"\"\"Converts a 4D tensor into a 2D tensor (so it can be fed to a fully-connected layer).\n",
    "    Args:\n",
    "        x: tensor with shape (N, H, W, C)\n",
    "    Returns:\n",
    "        tensor with shape (N, H*W*C)\n",
    "    \"\"\"\n",
    "    s = x.get_shape().as_list()\n",
    "    return tf.reshape(x, [s[0], -1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Network-assembly Function (Again)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def model(data):\n",
    "    \"\"\"Retrieves the weights and biases and constructs the computation graph with them.\n",
    "    Args:\n",
    "        data: A batch tensor of input examples K x H x W x D (where K is the batch size)\n",
    "    Returns: the network output K x C (where C is the number of categories)\n",
    "    \"\"\"\n",
    "    with tf.variable_scope('ConvPoolRelu1', reuse=True):\n",
    "        W = tf.get_variable(\"weights\")\n",
    "        B = tf.get_variable(\"biases\")\n",
    "        layer_1_output = conv_pool_relu_layer(data, W, B)\n",
    "    with tf.variable_scope('ConvPoolRelu2', reuse=True):\n",
    "        W = tf.get_variable(\"weights\")\n",
    "        B = tf.get_variable(\"biases\")\n",
    "        layer_2_output = conv_pool_relu_layer(layer_1_output, W, B)\n",
    "        flat_X = flatten_activation_map(layer_2_output)\n",
    "    with tf.variable_scope('FullyConnected3', reuse=True):\n",
    "        W = tf.get_variable(\"weights\")\n",
    "        B = tf.get_variable(\"biases\")\n",
    "        fc1_layer_output = tf.nn.relu(fc_layer(flat_X, W, B))\n",
    "    with tf.variable_scope('FullyConnected4', reuse=True):\n",
    "        W = tf.get_variable(\"weights\")\n",
    "        B = tf.get_variable(\"biases\")\n",
    "        fc2_layer_output = fc_layer(fc1_layer_output, W, B)\n",
    "    return fc2_layer_output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Network Output "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "cellView": "both",
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "collapsed": false,
    "id": "IZYv70SvvOan"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-7ca905260f0f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mtesting_graph\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGraph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mtesting_graph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_default\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mtest_prediction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msoftmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf_test_dataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "testing_graph = tf.Graph()\n",
    "with testing_graph.as_default():\n",
    "    test_prediction = tf.nn.softmax(model(tf_test_dataset))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Session-related Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "cellView": "both",
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "AgQDIREv02p1"
   },
   "outputs": [],
   "source": [
    "def accuracy(predictions, labels):\n",
    "    '''\n",
    "    \"Grades\" a list of predictions (like marking a multiple choice test).\n",
    "    Accepts a list of one-hot predictions and a list of ground truth labels (the right answers) \n",
    "    Args:\n",
    "        predictions: NxK float array of one-hot-encoded network output, \n",
    "                     where N is the number of examples and K is the number of categories\n",
    "        labels: NxK array of one-hot-encoded ground truth labels\n",
    "    Returns:\n",
    "        Percetage of correct predictions.\n",
    "    '''\n",
    "    return (100.0 * np.sum(np.argmax(predictions, 1) == np.argmax(labels, 1)) \n",
    "          / predictions.shape[0])\n",
    "\n",
    "def make_batch(data, max_size, batch_num):\n",
    "    n = data.shape[0]\n",
    "    offset = (batch_num * max_size) % n\n",
    "    return data[offset:offset+max_size]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing Session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from /tmp/model.ckpt.data-00000-of-00001\n"
     ]
    },
    {
     "ename": "DataLossError",
     "evalue": "Unable to open table file /tmp/model.ckpt.data-00000-of-00001: Data loss: not an sstable (bad magic number): perhaps your file is in a different file format and you need to use a different restore operator?\n\t [[Node: save/RestoreV2_4 = RestoreV2[dtypes=[DT_FLOAT], _device=\"/job:localhost/replica:0/task:0/cpu:0\"](_recv_save/Const_0, save/RestoreV2_4/tensor_names, save/RestoreV2_4/shape_and_slices)]]\n\t [[Node: save/RestoreV2_3/_11 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/gpu:0\", send_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device_incarnation=1, tensor_name=\"edge_42_save/RestoreV2_3\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/gpu:0\"]()]]\n\nCaused by op 'save/RestoreV2_4', defined at:\n  File \"/usr/lib/python3.5/runpy.py\", line 184, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/usr/lib/python3.5/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/home/me/.local/lib/python3.5/site-packages/ipykernel/__main__.py\", line 3, in <module>\n    app.launch_new_instance()\n  File \"/home/me/.local/lib/python3.5/site-packages/traitlets/config/application.py\", line 658, in launch_instance\n    app.start()\n  File \"/home/me/.local/lib/python3.5/site-packages/ipykernel/kernelapp.py\", line 474, in start\n    ioloop.IOLoop.instance().start()\n  File \"/home/me/.local/lib/python3.5/site-packages/zmq/eventloop/ioloop.py\", line 177, in start\n    super(ZMQIOLoop, self).start()\n  File \"/home/me/.local/lib/python3.5/site-packages/tornado/ioloop.py\", line 887, in start\n    handler_func(fd_obj, events)\n  File \"/home/me/.local/lib/python3.5/site-packages/tornado/stack_context.py\", line 275, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/home/me/.local/lib/python3.5/site-packages/zmq/eventloop/zmqstream.py\", line 440, in _handle_events\n    self._handle_recv()\n  File \"/home/me/.local/lib/python3.5/site-packages/zmq/eventloop/zmqstream.py\", line 472, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"/home/me/.local/lib/python3.5/site-packages/zmq/eventloop/zmqstream.py\", line 414, in _run_callback\n    callback(*args, **kwargs)\n  File \"/home/me/.local/lib/python3.5/site-packages/tornado/stack_context.py\", line 275, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/home/me/.local/lib/python3.5/site-packages/ipykernel/kernelbase.py\", line 276, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"/home/me/.local/lib/python3.5/site-packages/ipykernel/kernelbase.py\", line 228, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"/home/me/.local/lib/python3.5/site-packages/ipykernel/kernelbase.py\", line 390, in execute_request\n    user_expressions, allow_stdin)\n  File \"/home/me/.local/lib/python3.5/site-packages/ipykernel/ipkernel.py\", line 196, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/home/me/.local/lib/python3.5/site-packages/ipykernel/zmqshell.py\", line 501, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/home/me/.local/lib/python3.5/site-packages/IPython/core/interactiveshell.py\", line 2717, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/home/me/.local/lib/python3.5/site-packages/IPython/core/interactiveshell.py\", line 2821, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/home/me/.local/lib/python3.5/site-packages/IPython/core/interactiveshell.py\", line 2881, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-6-19d626d713a2>\", line 3, in <module>\n    new_saver = tf.train.import_meta_graph('/tmp/model.ckpt.meta')\n  File \"/home/me/.local/lib/python3.5/site-packages/tensorflow/python/training/saver.py\", line 1595, in import_meta_graph\n    **kwargs)\n  File \"/home/me/.local/lib/python3.5/site-packages/tensorflow/python/framework/meta_graph.py\", line 499, in import_scoped_meta_graph\n    producer_op_list=producer_op_list)\n  File \"/home/me/.local/lib/python3.5/site-packages/tensorflow/python/framework/importer.py\", line 308, in import_graph_def\n    op_def=op_def)\n  File \"/home/me/.local/lib/python3.5/site-packages/tensorflow/python/framework/ops.py\", line 2336, in create_op\n    original_op=self._default_original_op, op_def=op_def)\n  File \"/home/me/.local/lib/python3.5/site-packages/tensorflow/python/framework/ops.py\", line 1228, in __init__\n    self._traceback = _extract_stack()\n\nDataLossError (see above for traceback): Unable to open table file /tmp/model.ckpt.data-00000-of-00001: Data loss: not an sstable (bad magic number): perhaps your file is in a different file format and you need to use a different restore operator?\n\t [[Node: save/RestoreV2_4 = RestoreV2[dtypes=[DT_FLOAT], _device=\"/job:localhost/replica:0/task:0/cpu:0\"](_recv_save/Const_0, save/RestoreV2_4/tensor_names, save/RestoreV2_4/shape_and_slices)]]\n\t [[Node: save/RestoreV2_3/_11 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/gpu:0\", send_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device_incarnation=1, tensor_name=\"edge_42_save/RestoreV2_3\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/gpu:0\"]()]]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mDataLossError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m/home/me/.local/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1038\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1039\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1040\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/me/.local/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1020\u001b[0m                                  \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1021\u001b[0;31m                                  status, run_metadata)\n\u001b[0m\u001b[1;32m   1022\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.5/contextlib.py\u001b[0m in \u001b[0;36m__exit__\u001b[0;34m(self, type, value, traceback)\u001b[0m\n\u001b[1;32m     65\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m                 \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/me/.local/lib/python3.5/site-packages/tensorflow/python/framework/errors_impl.py\u001b[0m in \u001b[0;36mraise_exception_on_not_ok_status\u001b[0;34m()\u001b[0m\n\u001b[1;32m    465\u001b[0m           \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpywrap_tensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_Message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 466\u001b[0;31m           pywrap_tensorflow.TF_GetCode(status))\n\u001b[0m\u001b[1;32m    467\u001b[0m   \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mDataLossError\u001b[0m: Unable to open table file /tmp/model.ckpt.data-00000-of-00001: Data loss: not an sstable (bad magic number): perhaps your file is in a different file format and you need to use a different restore operator?\n\t [[Node: save/RestoreV2_4 = RestoreV2[dtypes=[DT_FLOAT], _device=\"/job:localhost/replica:0/task:0/cpu:0\"](_recv_save/Const_0, save/RestoreV2_4/tensor_names, save/RestoreV2_4/shape_and_slices)]]\n\t [[Node: save/RestoreV2_3/_11 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/gpu:0\", send_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device_incarnation=1, tensor_name=\"edge_42_save/RestoreV2_3\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/gpu:0\"]()]]",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mDataLossError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-19d626d713a2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSession\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtesting_graph\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mnew_saver\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimport_meta_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/tmp/model.ckpt.meta'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mnew_saver\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrestore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'/tmp/model.ckpt.data-00000-of-00001'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;31m#    saver = tf.train.Saver(session, \"/tmp/model.ckpt\", var_list=[])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mtotal_accuracy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/me/.local/lib/python3.5/site-packages/tensorflow/python/training/saver.py\u001b[0m in \u001b[0;36mrestore\u001b[0;34m(self, sess, save_path)\u001b[0m\n\u001b[1;32m   1455\u001b[0m     \u001b[0mlogging\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Restoring parameters from %s\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msave_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1456\u001b[0m     sess.run(self.saver_def.restore_op_name,\n\u001b[0;32m-> 1457\u001b[0;31m              {self.saver_def.filename_tensor_name: save_path})\n\u001b[0m\u001b[1;32m   1458\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1459\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mstaticmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/me/.local/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    776\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    777\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 778\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    779\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    780\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/me/.local/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    980\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    981\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m--> 982\u001b[0;31m                              feed_dict_string, options, run_metadata)\n\u001b[0m\u001b[1;32m    983\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    984\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/me/.local/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1030\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1031\u001b[0m       return self._do_call(_run_fn, self._session, feed_dict, fetch_list,\n\u001b[0;32m-> 1032\u001b[0;31m                            target_list, options, run_metadata)\n\u001b[0m\u001b[1;32m   1033\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1034\u001b[0m       return self._do_call(_prun_fn, self._session, handle, feed_dict,\n",
      "\u001b[0;32m/home/me/.local/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1050\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1051\u001b[0m           \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1052\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1053\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1054\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mDataLossError\u001b[0m: Unable to open table file /tmp/model.ckpt.data-00000-of-00001: Data loss: not an sstable (bad magic number): perhaps your file is in a different file format and you need to use a different restore operator?\n\t [[Node: save/RestoreV2_4 = RestoreV2[dtypes=[DT_FLOAT], _device=\"/job:localhost/replica:0/task:0/cpu:0\"](_recv_save/Const_0, save/RestoreV2_4/tensor_names, save/RestoreV2_4/shape_and_slices)]]\n\t [[Node: save/RestoreV2_3/_11 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/gpu:0\", send_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device_incarnation=1, tensor_name=\"edge_42_save/RestoreV2_3\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/gpu:0\"]()]]\n\nCaused by op 'save/RestoreV2_4', defined at:\n  File \"/usr/lib/python3.5/runpy.py\", line 184, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/usr/lib/python3.5/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/home/me/.local/lib/python3.5/site-packages/ipykernel/__main__.py\", line 3, in <module>\n    app.launch_new_instance()\n  File \"/home/me/.local/lib/python3.5/site-packages/traitlets/config/application.py\", line 658, in launch_instance\n    app.start()\n  File \"/home/me/.local/lib/python3.5/site-packages/ipykernel/kernelapp.py\", line 474, in start\n    ioloop.IOLoop.instance().start()\n  File \"/home/me/.local/lib/python3.5/site-packages/zmq/eventloop/ioloop.py\", line 177, in start\n    super(ZMQIOLoop, self).start()\n  File \"/home/me/.local/lib/python3.5/site-packages/tornado/ioloop.py\", line 887, in start\n    handler_func(fd_obj, events)\n  File \"/home/me/.local/lib/python3.5/site-packages/tornado/stack_context.py\", line 275, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/home/me/.local/lib/python3.5/site-packages/zmq/eventloop/zmqstream.py\", line 440, in _handle_events\n    self._handle_recv()\n  File \"/home/me/.local/lib/python3.5/site-packages/zmq/eventloop/zmqstream.py\", line 472, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"/home/me/.local/lib/python3.5/site-packages/zmq/eventloop/zmqstream.py\", line 414, in _run_callback\n    callback(*args, **kwargs)\n  File \"/home/me/.local/lib/python3.5/site-packages/tornado/stack_context.py\", line 275, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/home/me/.local/lib/python3.5/site-packages/ipykernel/kernelbase.py\", line 276, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"/home/me/.local/lib/python3.5/site-packages/ipykernel/kernelbase.py\", line 228, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"/home/me/.local/lib/python3.5/site-packages/ipykernel/kernelbase.py\", line 390, in execute_request\n    user_expressions, allow_stdin)\n  File \"/home/me/.local/lib/python3.5/site-packages/ipykernel/ipkernel.py\", line 196, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/home/me/.local/lib/python3.5/site-packages/ipykernel/zmqshell.py\", line 501, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/home/me/.local/lib/python3.5/site-packages/IPython/core/interactiveshell.py\", line 2717, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/home/me/.local/lib/python3.5/site-packages/IPython/core/interactiveshell.py\", line 2821, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/home/me/.local/lib/python3.5/site-packages/IPython/core/interactiveshell.py\", line 2881, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-6-19d626d713a2>\", line 3, in <module>\n    new_saver = tf.train.import_meta_graph('/tmp/model.ckpt.meta')\n  File \"/home/me/.local/lib/python3.5/site-packages/tensorflow/python/training/saver.py\", line 1595, in import_meta_graph\n    **kwargs)\n  File \"/home/me/.local/lib/python3.5/site-packages/tensorflow/python/framework/meta_graph.py\", line 499, in import_scoped_meta_graph\n    producer_op_list=producer_op_list)\n  File \"/home/me/.local/lib/python3.5/site-packages/tensorflow/python/framework/importer.py\", line 308, in import_graph_def\n    op_def=op_def)\n  File \"/home/me/.local/lib/python3.5/site-packages/tensorflow/python/framework/ops.py\", line 2336, in create_op\n    original_op=self._default_original_op, op_def=op_def)\n  File \"/home/me/.local/lib/python3.5/site-packages/tensorflow/python/framework/ops.py\", line 1228, in __init__\n    self._traceback = _extract_stack()\n\nDataLossError (see above for traceback): Unable to open table file /tmp/model.ckpt.data-00000-of-00001: Data loss: not an sstable (bad magic number): perhaps your file is in a different file format and you need to use a different restore operator?\n\t [[Node: save/RestoreV2_4 = RestoreV2[dtypes=[DT_FLOAT], _device=\"/job:localhost/replica:0/task:0/cpu:0\"](_recv_save/Const_0, save/RestoreV2_4/tensor_names, save/RestoreV2_4/shape_and_slices)]]\n\t [[Node: save/RestoreV2_3/_11 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/gpu:0\", send_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device_incarnation=1, tensor_name=\"edge_42_save/RestoreV2_3\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/gpu:0\"]()]]\n"
     ]
    }
   ],
   "source": [
    "testing_graph = tf.Graph()\n",
    "with tf.Session(graph=testing_graph) as session:\n",
    "    new_saver = tf.train.import_meta_graph('/tmp/model.ckpt.meta')\n",
    "    new_saver.restore(session, '/tmp/model.ckpt.data-00000-of-00001')\n",
    "#    saver = tf.train.Saver(session, \"/tmp/model.ckpt\", var_list=[])\n",
    "    total_accuracy = 0\n",
    "    n_test_cases = int(test_dataset.shape[0])\n",
    "    print(\"n_test_cases = %d\" % n_test_cases)\n",
    "    n_batches = int(n_test_cases / test_batch_size)\n",
    "    print(\"n_batches = \", str(n_batches))\n",
    "    for step in range(n_batches):\n",
    "        batch_data = make_batch(test_dataset, test_batch_size, step)\n",
    "        batch_labels = make_batch(test_labels, test_batch_size, step)\n",
    "        feed_dict = {tf_test_dataset: batch_data, tf_test_labels: batch_labels}\n",
    "        test_output_batch = session.run([test_prediction], feed_dict=feed_dict)[0]\n",
    "        this_batch_size = float(batch_labels.shape[0])\n",
    "        batch_accuracy = accuracy(np.asarray(test_output_batch), np.asarray(batch_labels))\n",
    "        total_accuracy = total_accuracy + batch_accuracy * this_batch_size / float(n_test_cases)\n",
    "\n",
    "    print('Test accuracy: %.1f%%' % total_accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Creates a graph.\n",
    "import tensorflow as tf\n",
    "a = tf.constant([1.0, 2.0, 3.0, 4.0, 5.0, 6.0], shape=[2, 3], name='a')\n",
    "b = tf.constant([1.0, 2.0, 3.0, 4.0, 5.0, 6.0], shape=[3, 2], name='b')\n",
    "c = tf.matmul(a, b)\n",
    "# Creates a session with log_device_placement set to True.\n",
    "sess = tf.Session(config=tf.ConfigProto(log_device_placement=True))\n",
    "# Runs the op.\n",
    "print(sess.run(c))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "!ls /tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "default_view": {},
   "name": "4_convolutions.ipynb",
   "provenance": [],
   "version": "0.3.2",
   "views": {}
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "navigate_num": "#000000",
    "navigate_text": "#333333",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700",
    "sidebar_border": "#EEEEEE",
    "wrapper_background": "#FFFFFF"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "355px",
    "width": "252px"
   },
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 4,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": false,
   "widenNotebook": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
